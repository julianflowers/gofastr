---
title: "gofastr"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  md_document:
    toc: true      
---


```{r, echo=FALSE}
desc <- suppressWarnings(readLines("DESCRIPTION"))
regex <- "(^Version:\\s+)(\\d+\\.\\d+\\.\\d+)"
loc <- grep(regex, desc)
ver <- gsub(regex, "\\2", desc[loc])
verbadge <- sprintf('<a href="https://img.shields.io/badge/Version-%s-orange.svg"><img src="https://img.shields.io/badge/Version-%s-orange.svg" alt="Version"/></a></p>', ver, ver)
````

[![Build Status](https://travis-ci.org/trinker/gofastr.svg?branch=master)](https://travis-ci.org/trinker/gofastr)
[![Coverage Status](https://coveralls.io/repos/trinker/gofastr/badge.svg?branch=master)](https://coveralls.io/r/trinker/gofastr?branch=master)
`r verbadge`

```{r, echo=FALSE, message=FALSE}
library(knitr)
knit_hooks$set(htmlcap = function(before, options, envir) {
  if(!before) {
    paste('<p class="caption"><b><em>',options$htmlcap,"</em></b></p>",sep="")
    }
    })
knitr::opts_knit$set(self.contained = TRUE, cache = FALSE)
knitr::opts_chunk$set(fig.path = "inst/figure/")
```

<img src="inst/gofastr_logo/r_gofastr.png" width="150" alt="readability Logo">  


**gofastr** is designed to do one thing really well...It harnesses the power of **data.table** and **stringi** to quickly generate **tm** `DocumentTermMatrix` and `TermDocumentMatrix` data structures. 

In my work I often get data in the form of large .csv files.  The `Corpus` structure is an unnecessary step that requires additional run time.  **gofastr** skips this step and uses **data.table** and **stringi** to quickly make the `DocumentTermMatrix` and `TermDocumentMatrix` data structures directly.  

# Function Usage

Functions typically fall into the task category of matrix (1) creation & (2) manipulating.  The main functions, task category, & descriptions are summarized in the table below:

| Function               |  Category    | Description                                                            |
|------------------------|--------------|------------------------------------------------------------------------|
| `q_tdm` & `q_tdm_stem` | creation     | `TermDocumentMatrix` from string vector                                |
| `q_dtm` & `q_dtm_stem` | creation     | `DocumentTermMatrix` from string vector                                |
| `remove_stopwords`     | manipulation | Remove stopwords and minimal character words from `TermDocumentMatrix`/`DocumentTermMatrix` |
| `filter_words`         | manipulation | Filter words from `TermDocumentMatrix`/`DocumentTermMatrix`            |
| `filter_tf_idf`        | manipulation | Filter low tf-idf words from `TermDocumentMatrix`/`DocumentTermMatrix` |
| `filter_documents`     | manipulation | Filter documents from a `TermDocumentMatrix`/`DocumentTermMatrix`      |
| `select_documents`     | manipulation | Select documents from `TermDocumentMatrix`/`DocumentTermMatrix`        |


# Installation

To download the development version of **gofastr**:

Download the [zip ball](https://github.com/trinker/gofastr/zipball/master) or [tar ball](https://github.com/trinker/gofastr/tarball/master), decompress and run `R CMD INSTALL` on it, or use the **pacman** package to install the development version:

```r
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("trinker/gofastr")
```

# Contact

You are welcome to:
* submit suggestions and bug-reports at: <https://github.com/trinker/gofastr/issues>
* send a pull request on: <https://github.com/trinker/gofastr/>
* compose a friendly e-mail to: <tyler.rinker@gmail.com>


# Demonstration

## Load Packages

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(gofastr, tm, magrittr)
```

## DocumentTerm/TermDocument Matrices

```{r}
(w <-with(presidential_debates_2012, q_dtm(dialogue, paste(time, tot, sep = "_"))))
(x <- with(presidential_debates_2012, q_tdm(dialogue, paste(time, tot, sep = "_"))))
```


## Stopwords

```{r}
with(presidential_debates_2012, q_dtm(dialogue, paste(time, tot, sep = "_"))) %>%
    remove_stopwords()

with(presidential_debates_2012, q_tdm(dialogue, paste(time, tot, sep = "_"))) %>%
    remove_stopwords()
```

## Weighting

```{r}
with(presidential_debates_2012, q_dtm(dialogue, paste(time, tot, sep = "_"))) %>%
    tm::weightTfIdf()
```


## Stemming

To stem words utilize `q_dtm_stem` and `q_tdm_stem` which utilize **SnowballC**'s stemmer under the hood.

```{r}
with(presidential_debates_2012, q_dtm_stem(dialogue, paste(time, tot, sep = "_"))) %>%
    remove_stopwords()
```


## Manipulating Words 

### Filter Out Low Occurring Words

To filter out words with counts below a threshold we use `filter_words`.

```{r}
with(presidential_debates_2012, q_dtm(dialogue, paste(time, person, sep = "_"))) %>%
    filter_words(5)
```

### Filter Out High Frequency (low information) Words

To filter out words with high frequency in all documents (thus low informaton) use  `filter_tf_idf`.

```{r}
with(presidential_debates_2012, q_dtm(dialogue, paste(time, person, sep = "_"))) %>%
    filter_tf_idf(.002)
```

## Manipulating Documents 

### Filter Out Low Occurring Documents 

To filter out documents with word counts below a threshold use `filter_documents`.  Remember the warning from above:

> `Warning message:`    
> `In tm::weightTfIdf(.) : empty document(s): time 1_88.1 time 2_52.1`

Here we use `filter_documents`' default (a document must have a row/column sum greater than 1) to eliminate the warning:

```{r}
with(presidential_debates_2012, q_dtm(dialogue, paste(time, tot, sep = "_"))) %>%
    filter_documents() %>%
    tm::weightTfIdf()
```

### Selecting Documents

To select only documents matching a regex use the `select_documents` function.

```{r}
with(presidential_debates_2012, q_dtm(dialogue, paste(time, person, sep = "_"))) %>%
    select_documents('romney', ignore.case=TRUE)

with(presidential_debates_2012, q_dtm(dialogue, paste(time, person, sep = "_"))) %>%
    select_documents('^(?!.*romney).*$', ignore.case = TRUE)
```

## Putting It Together

Of course we can chain matrix creation functions with several of the manipulation function to quickly prepare data for analysis.  Here I demonstrate preparing data for a topic model using ***gofaster**  and then the analysis. Finally, I plot the results and use the **LDAvis** package to interact with the results:

```{r, fig.width=10, fig.heigh=18}
pacman::p_load(tm, topicmodels, dplyr, tidyr, gofastr, devtools, LDAvis, ggplot2)

## Source topicmodels2LDAvis function
devtools::source_url("https://gist.githubusercontent.com/trinker/477d7ae65ff6ca73cace/raw/79dbc9d64b17c3c8befde2436fdeb8ec2124b07b/topicmodels2LDAvis")

data(presidential_debates_2012)

# Generate Stopwords 
stops <- c(
        tm::stopwords("english"),
        "governor", "president", "mister", "obama","romney"
    ) %>%
    prep_stopwords() 

## Create the DocumentTermMatrix
doc_term_mat <- pres_debates2012 %>%
    with(q_dtm_stem(dialogue, paste(person, time, sep = "_"))) %>%           
    remove_stopwords(stops, min.char = 3, stem = TRUE, denumber = TRUE)%>%                                                     
    filter_tf_idf(.001) %>%
    filter_words(4) %>%                       
    filter_documents() 

## Run the Model
lda_model <- topicmodels::LDA(doc_term_mat, 10)

## Plot the Topics Per Person_Time
topics <- posterior(lda_model, doc_term_mat)$topics
topic_dat <- add_rownames(as.data.frame(topics), "Person_Time")
colnames(topic_dat)[-1] <- apply(terms(lda_model, 10), 2, paste, collapse = ", ")

gather(topic_dat, Topic, Proportion, -c(Person_Time)) %>%
    separate(Person_Time, c("Person", "Time"), sep = "_") %>%
    mutate(Person = factor(Person, 
        levels = c("OBAMA", "ROMNEY", "LEHRER", "SCHIEFFER", "CROWLEY", "QUESTION" ))
    ) %>%
    ggplot(aes(weight=Proportion, x=Topic, fill=Topic)) +
        geom_bar() +
        coord_flip() +
        facet_grid(Person~Time) +
        guides(fill=FALSE) +
        xlab("Proportion")
```

```{r, eval=FALSE}
## LDAvis of Model
lda_model %>%
    topicmodels2LDAvis() %>%
    LDAvis::serVis()
```



## Comparing Timings

On a smaller `r nrow(presidential_debates_2012)` rows these are the time comparisons between **gofastr** and **tm** using `Sys.time`:

```{r}
pacman::p_load(gofastr, tm)

pd <- presidential_debates_2012
tic <- Sys.time()
rownames(pd) <- paste("docs", 1:nrow(pd))
pd[['groups']] <- with(pd, paste(time, tot, sep = "_"))
pd <- Corpus(DataframeSource(pd[, 5:6, drop=FALSE]))

(out <- DocumentTermMatrix(pd,
    control = list(
        tokenize=scan_tokenizer,
        stopwords=TRUE,
        removeNumbers = TRUE,
        removePunctuation = TRUE,
        wordLengths=c(3, Inf)
    )
) )
difftime(Sys.time(), tic)

tic <- Sys.time()
x <-with(presidential_debates_2012, q_dtm(dialogue, paste(time, tot, sep = "_")))
remove_stopwords(x)
difftime(Sys.time(), tic)
```

### With Stemming

```{r}
pd <- presidential_debates_2012
tic <- Sys.time()
rownames(pd) <- paste("docs", 1:nrow(pd))
pd[['groups']] <- with(pd, paste(time, tot, sep = "_"))
pd <- Corpus(DataframeSource(pd[, 5:6, drop=FALSE]))
pd <- tm_map(pd, stemDocument)

(out <- DocumentTermMatrix(pd,
    control = list(
        tokenize=scan_tokenizer,
        stopwords=TRUE,
        removeNumbers = TRUE,
        removePunctuation = TRUE,
        wordLengths=c(3, Inf)
    )
) )
difftime(Sys.time(), tic)

tic <- Sys.time()
x <-with(presidential_debates_2012, q_dtm_stem(dialogue, paste(time, tot, sep = "_")))
remove_stopwords(x, stem=TRUE)
difftime(Sys.time(), tic)
```
